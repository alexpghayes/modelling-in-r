# Proposed interface for supervised learning

Okay, now that we've taken a look at some interfaces and how they well they match up with the `model`/`model family` conception of modelling, let's imagine an interface that makes operations on `model` and `model family`s feel natural in R.

## What we want out of a modelling interface

- Work primarily with `model family` objects, where hyperparameter selection is abstracted as far away from the user as possible
- Scientists can provide smart cross-validation schemes when appropriate
- Users can easily select and interchange hyperparameter selection methods or specify their own
- Because hyperparameter / modelling technique specific settings are handled with reasonable defaults, users can easily work with large numbers of models are the same time via a consistent and unified interface
- Ensembling is easy
- Tidy and pipeable data structures

## (Tentative) Proposal

Since the `Scikit-Learn` interface is likely the most uniform and wide known interface, I think it's a good idea to use language from `Scikit-Learn` as much as possible.

```{r}
# object of class "knn". would like this to be cleaner
knn <- new_knn()

# fit model with specific values of hyperparameters. class c("knn", "model")
knn_model <- fit(knn, design, data, k = 13, metric = "euclidean")

# get hyperparameters via reasonable default. class c("knn", "model_family")
# design/data combo should work for:
#   - X, y (matrix, vector)
#   - formula, data frame
#   - recipe, data frame
#
# multiple dispatch would be nice here, curious how to implement
# this assumes default arguments for hyperparameter selection that need
# to be thought about more
knn_family <- fit(knn, design, data)

# TO THINK ABOUT: not sure if hyperparameter definition being the sole
# specification of model vs model_family output is a good idea

# for convenience and to provide a standard interface, we define a wrapper
# knn <- fit(new_knn(), design, data). now a machine learning package has
# an interface matching current idiomatic R for interested parties. but 
# new_* methods allow for convenient mapping of fit method, etc, that are
# easiest when model instantiation and fitting are distinct
knn_family <- knn(design, data)

# get the best knn model. class c("knn", "model")
best_knn_model <- extract_model(knn_family)

# predictions are of same type as outcome. i.e. numeric outcome 
# gives numeric predictions, factor outcome gives factor predictions
# the following would behavior equivalently
predictions <- predict(knn_family, newdata)
predictions <- predict(best_knn_model, newdata)

# for consistency with scikit-learn and overall sanity, for classification
class_probs <- predict_proba(knn_family, newdata)
```

`model_family` fields:

- `hp_results`: tibble of hyperparameters and resulting performance
- `hp_space`: specification of hyperparameter space
- `hp_strategy`: object like `trainControl` to specify hyperparameter search
- `best_model`: best model from hyperparameter search once trained

I don't have good ideas on how to specify `hp_space` at the moment.

I also think the following would highly increase usability

```{r}
bagged_model  <- bag(new_lasso(), new_ridge(), new_ols(), n = 50)
stacked_model <- stack(new_lasso(), new_ridge(), new_ols(),
                       metalearner = new_glm())
boosted_model <- boost(new_lasso(), new_ridge(), new_ols(), loss = "some_loss")
```

<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Some thoughts on modelling in R</title>
  <meta name="description" content="Some thoughts on modelling in R">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Some thoughts on modelling in R" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Some thoughts on modelling in R" />
  
  
  

<meta name="author" content="Alex Hayes">


<meta name="date" content="2017-12-19">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="existing-approaches-to-supervised-learning.html">
<link rel="next" href="extension-to-unsupervised-learning.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Motivation</a></li>
<li class="chapter" data-level="2" data-path="objects-in-a-grammar-of-supervised-learning.html"><a href="objects-in-a-grammar-of-supervised-learning.html"><i class="fa fa-check"></i><b>2</b> Objects in a grammar of supervised learning</a></li>
<li class="chapter" data-level="3" data-path="existing-approaches-to-supervised-learning.html"><a href="existing-approaches-to-supervised-learning.html"><i class="fa fa-check"></i><b>3</b> Existing approaches to supervised learning</a><ul>
<li class="chapter" data-level="3.1" data-path="existing-approaches-to-supervised-learning.html"><a href="existing-approaches-to-supervised-learning.html#scikit-learn"><i class="fa fa-check"></i><b>3.1</b> <code>Scikit-Learn</code></a></li>
<li class="chapter" data-level="3.2" data-path="existing-approaches-to-supervised-learning.html"><a href="existing-approaches-to-supervised-learning.html#caret"><i class="fa fa-check"></i><b>3.2</b> <code>caret</code></a></li>
<li class="chapter" data-level="3.3" data-path="existing-approaches-to-supervised-learning.html"><a href="existing-approaches-to-supervised-learning.html#mlr"><i class="fa fa-check"></i><b>3.3</b> <code>mlr</code></a></li>
<li class="chapter" data-level="3.4" data-path="existing-approaches-to-supervised-learning.html"><a href="existing-approaches-to-supervised-learning.html#idiomatic-modelling-in-r"><i class="fa fa-check"></i><b>3.4</b> Idiomatic modelling in R</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="proposed-interface-for-supervised-learning.html"><a href="proposed-interface-for-supervised-learning.html"><i class="fa fa-check"></i><b>4</b> Proposed interface for supervised learning</a><ul>
<li class="chapter" data-level="4.1" data-path="proposed-interface-for-supervised-learning.html"><a href="proposed-interface-for-supervised-learning.html#what-we-want-out-of-a-modelling-interface"><i class="fa fa-check"></i><b>4.1</b> What we want out of a modelling interface</a></li>
<li class="chapter" data-level="4.2" data-path="proposed-interface-for-supervised-learning.html"><a href="proposed-interface-for-supervised-learning.html#model-instantiation"><i class="fa fa-check"></i><b>4.2</b> Model Instantiation</a></li>
<li class="chapter" data-level="4.3" data-path="proposed-interface-for-supervised-learning.html"><a href="proposed-interface-for-supervised-learning.html#model-fitting"><i class="fa fa-check"></i><b>4.3</b> Model fitting</a></li>
<li class="chapter" data-level="4.4" data-path="proposed-interface-for-supervised-learning.html"><a href="proposed-interface-for-supervised-learning.html#prediction"><i class="fa fa-check"></i><b>4.4</b> Prediction</a></li>
<li class="chapter" data-level="4.5" data-path="proposed-interface-for-supervised-learning.html"><a href="proposed-interface-for-supervised-learning.html#ensembling"><i class="fa fa-check"></i><b>4.5</b> Ensembling</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="extension-to-unsupervised-learning.html"><a href="extension-to-unsupervised-learning.html"><i class="fa fa-check"></i><b>5</b> Extension to unsupervised learning</a><ul>
<li class="chapter" data-level="5.1" data-path="extension-to-unsupervised-learning.html"><a href="extension-to-unsupervised-learning.html#pipelines"><i class="fa fa-check"></i><b>5.1</b> Pipelines</a></li>
<li class="chapter" data-level="5.2" data-path="extension-to-unsupervised-learning.html"><a href="extension-to-unsupervised-learning.html#non-repeatable-mappings"><i class="fa fa-check"></i><b>5.2</b> Non-repeatable mappings</a></li>
<li class="chapter" data-level="5.3" data-path="extension-to-unsupervised-learning.html"><a href="extension-to-unsupervised-learning.html#invertible-mappings"><i class="fa fa-check"></i><b>5.3</b> Invertible Mappings</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="how-to-make-this-happen.html"><a href="how-to-make-this-happen.html"><i class="fa fa-check"></i><b>6</b> How to make this happen</a><ul>
<li class="chapter" data-level="6.1" data-path="how-to-make-this-happen.html"><a href="how-to-make-this-happen.html#community-standards"><i class="fa fa-check"></i><b>6.1</b> Community standards</a></li>
<li class="chapter" data-level="6.2" data-path="how-to-make-this-happen.html"><a href="how-to-make-this-happen.html#infrastructure-to-provide"><i class="fa fa-check"></i><b>6.2</b> Infrastructure to provide</a></li>
<li class="chapter" data-level="6.3" data-path="how-to-make-this-happen.html"><a href="how-to-make-this-happen.html#misc"><i class="fa fa-check"></i><b>6.3</b> Misc</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Some thoughts on modelling in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="proposed-interface-for-supervised-learning" class="section level1">
<h1><span class="header-section-number">Part 4</span> Proposed interface for supervised learning</h1>
<p>Okay, now that we’ve taken a look at some interfaces and how they well they match up with the <code>model</code>/<code>model family</code> conception of modelling, let’s imagine an interface that makes operations on <code>model</code> and <code>model family</code>s feel natural in R.</p>
<div id="what-we-want-out-of-a-modelling-interface" class="section level2">
<h2><span class="header-section-number">4.1</span> What we want out of a modelling interface</h2>
<ul>
<li>Scientists can provide smart cross-validation schemes when appropriate</li>
<li>Users can easily select and interchange hyperparameter selection methods or specify their own</li>
<li>Because hyperparameter / modelling technique specific settings are handled with reasonable defaults, users can easily work with large numbers of models are the same time via a consistent and unified interface</li>
<li>Ensembling is easy (in particular, I think we want it to be easy to build <code>SuperLearner</code> based packages off the provided model objects)</li>
<li>Tidy and pipeable data structures</li>
<li>Work primarily with <code>model family</code> objects, where hyperparameter selection is abstracted as far away from the user as possible. The less time users have to spend writing the same old hyperparameter optimization code, the easier it is for them to fall into the pit of success.</li>
<li>Provide <a href="https://papers.nips.cc/paper/5872-efficient-and-robust-automated-machine-learning.pdf">metalearned</a> hyperparameter values like <code>auto-sklearn</code> does (i.e. default hyperparameter search starts with hyperparameters known to work well on similar datasets)</li>
</ul>
<p><img src="figures/metalearning_performance.png" width="448" /></p>
<p>Since the <code>Scikit-Learn</code> interface is likely the most uniform and wide known interface, I think it’s a good idea to use language from <code>Scikit-Learn</code> as much as possible.</p>
</div>
<div id="model-instantiation" class="section level2">
<h2><span class="header-section-number">4.2</span> Model Instantiation</h2>
<p>Let’s demonstrate a potential interface assuming we’d like to use KNN.</p>
<p>In terms of implementation, I think things will be easiest if each model has a dedicated object initialization function. This function should return an object of class <code>&quot;knn&quot;</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knn &lt;-<span class="st"> </span><span class="kw">new_knn</span>()  <span class="co"># instantiation functions need a better name</span></code></pre></div>
<p>But since the current paradigm in R doesn’t involve instantiating model objects before fitting them, I think it would also be good to provide a wrapper called <code>knn</code> that first creates a <code>knn</code> object and then fits it. That is</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knn_family &lt;-<span class="st"> </span><span class="kw">knn</span>(design, data)</code></pre></div>
<p>would be equivalent to</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knn &lt;-<span class="st"> </span><span class="kw">new_knn</span>()
knn_family &lt;-<span class="st"> </span><span class="kw">fit</span>(knn, design, data)

<span class="co"># or, with pipes</span>

knn_family &lt;-<span class="st"> </span><span class="kw">new_knn</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">fit</span>(design, data)</code></pre></div>
<p>where <code>design</code>/<code>data</code> is some combination of:</p>
<ul>
<li>X, y (matrix, vector)</li>
<li>formula, data frame</li>
<li>recipe, data frame</li>
</ul>
</div>
<div id="model-fitting" class="section level2">
<h2><span class="header-section-number">4.3</span> Model fitting</h2>
<p>Model fitting is the most important and most complex part of the interface, and this is where I’m least happy with what’s I’ve come up with at the moment. To fit a model, we need to specify:</p>
<ul>
<li>A design matrix and data</li>
<li>A hyperparameter space</li>
<li>A hyperparameter search algorithm</li>
<li>A resampling/performance assessment strategy</li>
</ul>
<p>I believe each of these is a major component that deserves it’s own object. The <code>recipes</code> package deals with specifying data design.</p>
<p>There are several R packages that allow for specification of a hyperparameter space, such as <code>mlr</code>/<code>mlrMBO</code> (<a href="https://arxiv.org/pdf/1703.03373.pdf">details here</a>). The tools there provide seem quite useful, but again I’m not a fan of the interface. There are a huge number of packages that do this in Python though, for example <a href="https://github.com/HIPS/Spearmint">Spearmint</a>.</p>
<p>For now, I’ll pretend <code>hp_space()</code> generates a reasonable hyperparameter space object, and that <code>gaussian_process_opt()</code> is a search strategy that knows how to interface with <code>hp_space</code> objects.</p>
<p>I’ll also assume that there is an <code>rsample_spec</code> object that specifies a resampling strategy and some performance metric used to determine which <code>model</code> has the best performance. Maybe this would turn out to be a combination of an <code>rsample::rset</code> generator with a scoring function.</p>
<p>To fit a <code>model</code> object, we could then do any of the following, returning an object of class <code>knn_model</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knn_model &lt;-<span class="st"> </span><span class="kw">knn</span>(design, data, <span class="kw">hp_space</span>(<span class="dt">k =</span> <span class="dv">13</span>, <span class="dt">metric =</span> <span class="st">&quot;euclidean&quot;</span>))

knn_model &lt;-<span class="st"> </span><span class="kw">fit</span>(<span class="kw">new_knn</span>(), design, data,
                 <span class="dt">hp_space =</span> <span class="kw">hp_space</span>(<span class="dt">k =</span> <span class="dv">13</span>, <span class="dt">metric =</span> <span class="st">&quot;euclidean&quot;</span>))

knn_model &lt;-<span class="st"> </span><span class="kw">new_knn</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">add_design</span>(recipe, data) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">add_hp_space</span>(<span class="dt">k =</span> <span class="dv">13</span>, <span class="dt">metric =</span> <span class="st">&quot;euclidean&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">fit</span>()</code></pre></div>
<p>Since we are fitting a <code>model</code> rather than <code>model_family</code> here we don’t need to specify a hyperparameter search algorithm or a performance assessment specification.</p>
<p>That is, you get a <code>model</code> back when there is a single set of hyperparameters in the <code>hp_space</code> and a <code>model_family</code> anytime the <code>hp_space</code> specifies multiple/infinite hyperparameter combinations.</p>
<p>To fit <code>model_family</code> objects, the following would be equivalent</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knn_family &lt;-<span class="st"> </span><span class="kw">knn</span>(design, data)

<span class="co"># and showing default arguments</span>

knn_family &lt;-<span class="st"> </span><span class="kw">fit</span>(<span class="kw">new_knn</span>(), design, data,
                  <span class="dt">hp_space =</span> default_knn_hp_space,
                  <span class="dt">hp_strategy =</span> gaussian_process_opt,
                  <span class="dt">resampling_strategy =</span> default_rset_specification)</code></pre></div>
<p>For users departing from the defaults, this might look like</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">hyperparams &lt;-<span class="st"> </span><span class="kw">hp_space</span>(<span class="dt">k =</span> <span class="dv">3</span><span class="op">:</span><span class="dv">4</span>, <span class="dt">metric =</span> <span class="kw">c</span>(<span class="st">&quot;euclidean&quot;</span>, <span class="st">&quot;manhattan&quot;</span>))
resamp_spec &lt;-<span class="st"> </span><span class="kw">resampling_spec</span>(<span class="dt">score =</span> <span class="st">&quot;mae&quot;</span>, <span class="dt">sampling =</span> <span class="st">&quot;bootstrap&quot;</span>, <span class="dt">reps =</span> <span class="dv">10</span>)

knn_family &lt;-<span class="st"> </span><span class="kw">new_knn</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">add_design</span>(recipe, data) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">add_hp_space</span>(hyperparams) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">add_hp_search</span>(hyperband) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">add_resampling</span>(resamp_spec) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">fit</span>()</code></pre></div>
<p>If you wanted to do inference on the best <code>model</code> in <code>knn_family</code>, you could get it with</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">best_knn_model &lt;-<span class="st"> </span><span class="kw">extract_model</span>(knn_family)</code></pre></div>
<p>This still leaves out a bunch of details. For example (I’ll update the list below as I think of more things):</p>
<ul>
<li>Observation weights and offsets. My thought is that <code>recipes</code> should handle this.</li>
<li>A subset of the data to work on. Again, <code>recipes</code> should handle this to separate modelling fitting and data preprocessing.</li>
</ul>
</div>
<div id="prediction" class="section level2">
<h2><span class="header-section-number">4.4</span> Prediction</h2>
<p>Default predict methods should always return predictions of the same type as the input data. That is, if you specify a numeric outcome, you get a numeric prediction, if you specify a factor outcome, you get a factor prediction. This makes it easy for users to assess model performance, which is probably the first thing you want to do do after predicting.</p>
<p>This would look like</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">predictions &lt;-<span class="st"> </span><span class="kw">predict</span>(knn_family, newdata)
predictions &lt;-<span class="st"> </span><span class="kw">predict</span>(best_knn_model, newdata)</code></pre></div>
<p>For sanity and consistency with <code>Scikit-Learn</code>, I think it would be good to add a new generic <code>predict_proba</code> to get class probabilities for classification problems</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">class_probs &lt;-<span class="st"> </span><span class="kw">predict_proba</span>(knn_family, newdata)</code></pre></div>
</div>
<div id="ensembling" class="section level2">
<h2><span class="header-section-number">4.5</span> Ensembling</h2>
<p>I also think the following would highly increase usability</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">bagged_model  &lt;-<span class="st"> </span><span class="kw">bag</span>(<span class="kw">new_lasso</span>(), <span class="kw">new_ridge</span>(), <span class="kw">new_ols</span>(), <span class="dt">n =</span> <span class="dv">50</span>)
stacked_model &lt;-<span class="st"> </span><span class="kw">stack</span>(<span class="kw">new_lasso</span>(), <span class="kw">new_ridge</span>(), <span class="kw">new_ols</span>(),
                       <span class="dt">metalearner =</span> <span class="kw">new_glm</span>())
boosted_model &lt;-<span class="st"> </span><span class="kw">boost</span>(<span class="kw">new_lasso</span>(), <span class="kw">new_ridge</span>(), <span class="kw">new_ols</span>(), <span class="dt">loss =</span> <span class="st">&quot;some_loss&quot;</span>)</code></pre></div>
<p>I’m not sure if <code>bagged_model</code>, <code>stacked_model</code> and <code>boosted_model</code> are <code>model</code>s or <code>model_family</code>s, or something else entirely.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="existing-approaches-to-supervised-learning.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="extension-to-unsupervised-learning.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

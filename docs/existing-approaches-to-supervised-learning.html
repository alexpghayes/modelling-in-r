<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Some thoughts on modelling in R</title>
  <meta name="description" content="This document contains some initial thoughts about what a grammar of modelling might look like in R.">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Some thoughts on modelling in R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This document contains some initial thoughts about what a grammar of modelling might look like in R." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Some thoughts on modelling in R" />
  
  <meta name="twitter:description" content="This document contains some initial thoughts about what a grammar of modelling might look like in R." />
  

<meta name="author" content="Alex">


<meta name="date" content="2017-12-15">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="objects-in-a-grammar-of-supervised-learning.html">
<link rel="next" href="proposed-interface-for-supervised-learning.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Motivation</a></li>
<li class="chapter" data-level="2" data-path="objects-in-a-grammar-of-supervised-learning.html"><a href="objects-in-a-grammar-of-supervised-learning.html"><i class="fa fa-check"></i><b>2</b> Objects in a grammar of supervised learning</a></li>
<li class="chapter" data-level="3" data-path="existing-approaches-to-supervised-learning.html"><a href="existing-approaches-to-supervised-learning.html"><i class="fa fa-check"></i><b>3</b> Existing approaches to supervised learning</a><ul>
<li class="chapter" data-level="3.1" data-path="existing-approaches-to-supervised-learning.html"><a href="existing-approaches-to-supervised-learning.html#scikit-learn"><i class="fa fa-check"></i><b>3.1</b> <code>Scikit-Learn</code></a></li>
<li class="chapter" data-level="3.2" data-path="existing-approaches-to-supervised-learning.html"><a href="existing-approaches-to-supervised-learning.html#caret"><i class="fa fa-check"></i><b>3.2</b> <code>caret</code></a></li>
<li class="chapter" data-level="3.3" data-path="existing-approaches-to-supervised-learning.html"><a href="existing-approaches-to-supervised-learning.html#mlr"><i class="fa fa-check"></i><b>3.3</b> <code>mlr</code></a></li>
<li class="chapter" data-level="3.4" data-path="existing-approaches-to-supervised-learning.html"><a href="existing-approaches-to-supervised-learning.html#idiomatic-r-code-for-single-model"><i class="fa fa-check"></i><b>3.4</b> Idiomatic R code for single model</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="proposed-interface-for-supervised-learning.html"><a href="proposed-interface-for-supervised-learning.html"><i class="fa fa-check"></i><b>4</b> Proposed interface for supervised learning</a><ul>
<li class="chapter" data-level="4.1" data-path="proposed-interface-for-supervised-learning.html"><a href="proposed-interface-for-supervised-learning.html#proposal-tentative-start"><i class="fa fa-check"></i><b>4.1</b> Proposal (tentative start)</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="extension-to-unsupervised-learning.html"><a href="extension-to-unsupervised-learning.html"><i class="fa fa-check"></i><b>5</b> Extension to unsupervised learning</a><ul>
<li class="chapter" data-level="5.1" data-path="extension-to-unsupervised-learning.html"><a href="extension-to-unsupervised-learning.html#pipelines"><i class="fa fa-check"></i><b>5.1</b> Pipelines?</a><ul>
<li class="chapter" data-level="5.1.1" data-path="extension-to-unsupervised-learning.html"><a href="extension-to-unsupervised-learning.html#special-cases"><i class="fa fa-check"></i><b>5.1.1</b> Special cases</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="utilities-and-other-important-functionality.html"><a href="utilities-and-other-important-functionality.html"><i class="fa fa-check"></i><b>6</b> Utilities and other important functionality</a></li>
<li class="chapter" data-level="7" data-path="how-to-make-this-happen.html"><a href="how-to-make-this-happen.html"><i class="fa fa-check"></i><b>7</b> How to make this happen</a><ul>
<li class="chapter" data-level="7.1" data-path="how-to-make-this-happen.html"><a href="how-to-make-this-happen.html#how-to-implement-new-models"><i class="fa fa-check"></i><b>7.1</b> How to implement new models</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Some thoughts on modelling in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="existing-approaches-to-supervised-learning" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Existing approaches to supervised learning</h1>
<div id="scikit-learn" class="section level2">
<h2><span class="header-section-number">3.1</span> <code>Scikit-Learn</code></h2>
<p>In Scikit-Learn we can fit and predict with <code>model</code> objects quite intuitively:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python"><span class="im">from</span> sklearn <span class="im">import</span> neighbors
knn <span class="op">=</span> neighbors.KNeighborsClassifier(n_neighbors<span class="op">=</span>k)
knn.fit(X_train, y_train)
predictions <span class="op">=</span> knn.predict(X_test)</code></pre></div>
<p>However, I find the abstractions to work with <code>model family</code>s less satisfying. Considering the KNN model family where we use random search to select a value of <span class="math inline">\(k\)</span>, which looks something like:</p>
<div class="sourceCode"><pre class="sourceCode python"><code class="sourceCode python">hyperparameter_space <span class="op">=</span> {
    <span class="st">&#39;n_neighbors&#39;</span>: sp_randint(<span class="dv">1</span>, <span class="dv">31</span>)  <span class="co"># pick k in [1, 2, ..., 30]</span>
}

knn <span class="op">=</span> RandomizedSearchCV(KNeighborsClassifier(),
                         param_distributions<span class="op">=</span>hyperparameter_space)

knn.fit(X, y)</code></pre></div>
<p>I find this suboptimal for a couple reasons:</p>
<ul>
<li>We have to manually specify the hyperparameter space even though there are sane defaults</li>
<li>If we wanted to use grid search or a different hyperparameter selection method, we’d have to change the specification of the hyperparameter space (i.e. we’d have to pass a list of values for <code>n_neighbors</code> rather than a distribution function for a grid search, etc, etc)</li>
<li>This doesn’t allow us to take advantage of structure in the hyperparameter space. For example, with KNN, assuming we aren’t doing any fancy approximation methods, we really want to calculate pairwise distances exactly once, and then reuse that pairwise distance information to select <span class="math inline">\(k\)</span>. Instead we recalculate pairwise distances for each <span class="math inline">\(k\)</span>, which is inefficient. Similarly, for penalized regression, we have to refit the model for each <span class="math inline">\(\lambda\)</span> rather than efficiently fitting an entire solution path all at once.</li>
</ul>
<p>That is, the KNN model family abstraction is closely tied to the hyperparameter selection technique, when it would be cleaner to specify that we want to work with the KNN model family and then plug in whichever hyperparameter selection technique we choose.</p>
<p>There are some things that <code>Scikit-Learn</code> does really well though:</p>
<ul>
<li>It has an extremely consistent interface that has been established as a communal standard within the Python community</li>
<li>There are extension libraries that make automated machine learning and ensemble creation easy and pleasant</li>
</ul>
<p>Lastly, it’s worth noting that in <code>Scikit-Learn</code> you have instantiate a <code>KNeighborsClassifier</code> object and afterward call <code>fit</code> on it. This differs from R where a dominant paradigm is to instantiate a model and train it with a single class along the lines of</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knn_model &lt;-<span class="st"> </span><span class="kw">knn_classifer</span>(y <span class="op">~</span><span class="st"> </span>., data, <span class="dt">k =</span> <span class="dv">5</span>)</code></pre></div>
</div>
<div id="caret" class="section level2">
<h2><span class="header-section-number">3.2</span> <code>caret</code></h2>
<p>In my mind, the <code>caret</code> library most closely matches my intuition about working with <code>model family</code>s rather than <code>model</code>s.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(caret)

<span class="co"># specify 10-fold CV repeated 10 times are hyperparameter selection strategy</span>
fitControl &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;repeatedcv&quot;</span>,
                           <span class="dt">number =</span> <span class="dv">10</span>,
                           <span class="dt">repeats =</span> <span class="dv">10</span>)

knn_model &lt;-<span class="st"> </span><span class="kw">train</span>(y <span class="op">~</span><span class="st"> </span>.,
                   <span class="dt">data =</span> train_df, 
                   <span class="dt">method =</span> <span class="st">&quot;knn&quot;</span>, 
                   <span class="dt">trControl =</span> fitControl)</code></pre></div>
<p>Some things I like about the <code>caret</code> interface:</p>
<ul>
<li>The hyperparameter selection strategy is an argument to the fit method</li>
<li>Reasonable defaults are provided for some hyperparameters, so it occasionally does feel like you’re working with a <code>model family</code> that has abstracted away hyperparameter selection</li>
<li><code>caret</code> takes advantage of built in, smart hyperparameter selection like <code>cv.glmnet</code> instead of manually checking values of <span class="math inline">\(\lambda\)</span></li>
</ul>
<p>Some things I don’t like about the <code>caret</code> interface:</p>
<ul>
<li>The default hyperparameter search is not an extensive enough to ignore hyperparameter selection in the majority of cases and so you end up specifying a tuning grid most of the time. Ideally I think all models should function with default hyperparameter selection as in <code>h2o.automl()</code></li>
<li>The result of <code>train</code> is an object of class <code>train</code>. That is, you know it’s a model family object, but the precise modelling technique is stored as a string. This means you have to write wrapper code if you want to add a model to the <code>caret</code> interface (i.e. it’s a nice package to work with, but it probably isn’t a great API to set as a communal standard for scientist producing packages)</li>
<li>Ensembling is hard. There’s the <code>caretEnsemble</code> extension but I find the interface a messy.</li>
</ul>
<p>It’s also worth noting that <code>caret</code> doesn’t require object instantiation like <code>Scikit-Learn</code> does.</p>
</div>
<div id="mlr" class="section level2">
<h2><span class="header-section-number">3.3</span> <code>mlr</code></h2>
<p>Briefly, the <code>mlr</code> library is similar to <code>caret</code>, but with the following interface:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">task =<span class="st"> </span><span class="kw">makeClassifTask</span>(<span class="dt">data =</span> iris, <span class="dt">target =</span> <span class="st">&quot;Species&quot;</span>)
lrn =<span class="st"> </span><span class="kw">makeLearner</span>(<span class="st">&quot;classif.lda&quot;</span>)

n =<span class="st"> </span><span class="kw">nrow</span>(iris)
train.set =<span class="st"> </span><span class="kw">sample</span>(n, <span class="dt">size =</span> <span class="dv">2</span><span class="op">/</span><span class="dv">3</span><span class="op">*</span>n)
test.set =<span class="st"> </span><span class="kw">setdiff</span>(<span class="dv">1</span><span class="op">:</span>n, train.set)

model =<span class="st"> </span><span class="kw">train</span>(lrn, task, <span class="dt">subset =</span> train.set)

pred =<span class="st"> </span><span class="kw">predict</span>(model, <span class="dt">task =</span> task, <span class="dt">subset =</span> test.set)
<span class="kw">performance</span>(pred, <span class="dt">measures =</span> <span class="kw">list</span>(mmce, acc))</code></pre></div>
<p>I think this interface has issues similar to <code>caret</code>s interface. In particular, I am strongly against manually specifying the learning task and think that the task at hand should be inferred from the class of the data object. I think prediction should be model-centric rather than outcome centric.</p>
</div>
<div id="idiomatic-r-code-for-single-model" class="section level2">
<h2><span class="header-section-number">3.4</span> Idiomatic R code for single model</h2>
<p>Let’s consider an imaginary package using an idiomatic R interface that performs lasso regression. A nicely written package might have an interface like so</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(lasso)

lasso_object &lt;-<span class="st"> </span><span class="kw">lasso</span>(X, y, <span class="dt">lambda =</span> <span class="fl">0.01</span>)
<span class="kw">predict</span>(lasso_object, X_new)</code></pre></div>
<p>Since there are efficient ways to cross-validate <span class="math inline">\(\lambda\)</span> for lasso regression, the package would likely also implement an interface like</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lasso_cv_object &lt;-<span class="st"> </span><span class="kw">lasso_cv</span>(X, y)
<span class="kw">predict</span>(lasso_cv_object)</code></pre></div>
<p>that would automatically select an optimal value of <span class="math inline">\(\lambda\)</span>. A nice package author would make <code>lasso</code> and <code>lasso_cv</code> generics and would also implement formula or even <a href="https://github.com/topepo/recipes">recipe</a> interfaces to the model, like so</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lasso_object &lt;-<span class="st"> </span><span class="kw">lasso</span>(y <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> df, <span class="dt">lambda =</span> <span class="fl">0.01</span>)
lasso_cv_object &lt;-<span class="st"> </span><span class="kw">lasso_cv</span>(y <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> df)</code></pre></div>
<p>I think this is a clean interface and a good standard to keep until something better comes along. In the long term, I would like the community standard for modelling to change, because:</p>
<ul>
<li><p>When there isn’t a smart way to select to perform cross-validation, you have to write hyperparameter search code yourself, and small variations in interface design mean you have to do this for each different model you work with</p></li>
<li><p>Unless there’s a <code>recipe</code> interface to the <code>lasso_cv</code> function there isn’t a way to do principled preprocessing when resampling to estimate prediction error</p></li>
<li><p>Most of the time you work with multiple models, so it is incredible convenient to be able to do something like:</p></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model_familys &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="kw">lasso</span>(), <span class="kw">ridge</span>(), <span class="kw">OLS</span>())
train_models &lt;-<span class="st"> </span><span class="kw">map</span>(models, <span class="op">~</span><span class="kw">fit</span>(model_familys, y <span class="op">~</span><span class="st"> </span>., data))</code></pre></div>
<p>but this isn’t possible because each function has it’s own version of <code>fit</code>.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="objects-in-a-grammar-of-supervised-learning.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="proposed-interface-for-supervised-learning.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
